{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as scs\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approach_vertical</th>\n",
       "      <th>vertical_jump</th>\n",
       "      <th>three_quarter_court_sprint</th>\n",
       "      <th>four_way_agility</th>\n",
       "      <th>reaction_shuttle</th>\n",
       "      <th>bamscore</th>\n",
       "      <th>wingspan</th>\n",
       "      <th>reach</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>body_comp</th>\n",
       "      <th>hand_length</th>\n",
       "      <th>hand_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.5</td>\n",
       "      <td>28.5</td>\n",
       "      <td>3.376</td>\n",
       "      <td>11.471</td>\n",
       "      <td>3.669</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>72.75</td>\n",
       "      <td>94.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>174.4</td>\n",
       "      <td>9.8</td>\n",
       "      <td>7.50</td>\n",
       "      <td>8.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.5</td>\n",
       "      <td>21.5</td>\n",
       "      <td>3.486</td>\n",
       "      <td>12.114</td>\n",
       "      <td>3.355</td>\n",
       "      <td>1865.0</td>\n",
       "      <td>82.00</td>\n",
       "      <td>104.5</td>\n",
       "      <td>79.5</td>\n",
       "      <td>188.4</td>\n",
       "      <td>21.9</td>\n",
       "      <td>7.50</td>\n",
       "      <td>8.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3.230</td>\n",
       "      <td>12.036</td>\n",
       "      <td>3.562</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>81.50</td>\n",
       "      <td>99.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>196.5</td>\n",
       "      <td>13.9</td>\n",
       "      <td>9.00</td>\n",
       "      <td>9.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.370</td>\n",
       "      <td>12.509</td>\n",
       "      <td>3.173</td>\n",
       "      <td>1902.0</td>\n",
       "      <td>79.50</td>\n",
       "      <td>101.0</td>\n",
       "      <td>77.5</td>\n",
       "      <td>205.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>8.25</td>\n",
       "      <td>9.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3.389</td>\n",
       "      <td>12.724</td>\n",
       "      <td>3.316</td>\n",
       "      <td>1903.0</td>\n",
       "      <td>77.00</td>\n",
       "      <td>101.5</td>\n",
       "      <td>78.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>15.4</td>\n",
       "      <td>8.00</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   approach_vertical  vertical_jump  three_quarter_court_sprint  \\\n",
       "0               33.5           28.5                       3.376   \n",
       "1               30.5           21.5                       3.486   \n",
       "2               37.0           31.0                       3.230   \n",
       "3               29.0           23.0                       3.370   \n",
       "4               31.0           26.0                       3.389   \n",
       "\n",
       "   four_way_agility  reaction_shuttle  bamscore  wingspan  reach  height  \\\n",
       "0            11.471             3.669    2003.0     72.75   94.0    70.0   \n",
       "1            12.114             3.355    1865.0     82.00  104.5    79.5   \n",
       "2            12.036             3.562    2005.0     81.50   99.0    74.0   \n",
       "3            12.509             3.173    1902.0     79.50  101.0    77.5   \n",
       "4            12.724             3.316    1903.0     77.00  101.5    78.0   \n",
       "\n",
       "   weight  body_comp  hand_length  hand_width  \n",
       "0   174.4        9.8         7.50        8.25  \n",
       "1   188.4       21.9         7.50        8.75  \n",
       "2   196.5       13.9         9.00        9.50  \n",
       "3   205.0       10.6         8.25        9.25  \n",
       "4   180.0       15.4         8.00       10.00  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('bam_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approach_vertical</th>\n",
       "      <th>vertical_jump</th>\n",
       "      <th>three_quarter_court_sprint</th>\n",
       "      <th>four_way_agility</th>\n",
       "      <th>reaction_shuttle</th>\n",
       "      <th>bamscore</th>\n",
       "      <th>wingspan</th>\n",
       "      <th>reach</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>body_comp</th>\n",
       "      <th>hand_length</th>\n",
       "      <th>hand_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1059.000000</td>\n",
       "      <td>1059.000000</td>\n",
       "      <td>1059.000000</td>\n",
       "      <td>1059.000000</td>\n",
       "      <td>1059.000000</td>\n",
       "      <td>1059.000000</td>\n",
       "      <td>1059.000000</td>\n",
       "      <td>1059.000000</td>\n",
       "      <td>1059.000000</td>\n",
       "      <td>1059.000000</td>\n",
       "      <td>1059.000000</td>\n",
       "      <td>1059.000000</td>\n",
       "      <td>1059.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>31.829615</td>\n",
       "      <td>25.860157</td>\n",
       "      <td>3.467047</td>\n",
       "      <td>12.247189</td>\n",
       "      <td>3.505243</td>\n",
       "      <td>1890.976326</td>\n",
       "      <td>78.089797</td>\n",
       "      <td>98.714180</td>\n",
       "      <td>75.094195</td>\n",
       "      <td>181.077153</td>\n",
       "      <td>15.007786</td>\n",
       "      <td>8.049381</td>\n",
       "      <td>8.876189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.423395</td>\n",
       "      <td>3.065653</td>\n",
       "      <td>0.335502</td>\n",
       "      <td>0.652726</td>\n",
       "      <td>0.273783</td>\n",
       "      <td>134.866028</td>\n",
       "      <td>5.143227</td>\n",
       "      <td>5.824608</td>\n",
       "      <td>5.128197</td>\n",
       "      <td>26.875151</td>\n",
       "      <td>6.016857</td>\n",
       "      <td>0.533210</td>\n",
       "      <td>0.638452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>2.950000</td>\n",
       "      <td>10.359000</td>\n",
       "      <td>2.914000</td>\n",
       "      <td>1343.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>37.875000</td>\n",
       "      <td>10.300000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>3.339500</td>\n",
       "      <td>11.806000</td>\n",
       "      <td>3.348000</td>\n",
       "      <td>1811.000000</td>\n",
       "      <td>75.500000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>72.750000</td>\n",
       "      <td>165.250000</td>\n",
       "      <td>10.400000</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>8.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31.829615</td>\n",
       "      <td>25.860157</td>\n",
       "      <td>3.424000</td>\n",
       "      <td>12.244000</td>\n",
       "      <td>3.492000</td>\n",
       "      <td>1899.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>98.714180</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>179.600000</td>\n",
       "      <td>14.979496</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.876189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>3.537500</td>\n",
       "      <td>12.658000</td>\n",
       "      <td>3.634000</td>\n",
       "      <td>1981.000000</td>\n",
       "      <td>80.500000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>77.250000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>18.900000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>43.500000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>9.954000</td>\n",
       "      <td>14.775000</td>\n",
       "      <td>6.759000</td>\n",
       "      <td>2298.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>190.700000</td>\n",
       "      <td>303.400000</td>\n",
       "      <td>34.500000</td>\n",
       "      <td>9.750000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       approach_vertical  vertical_jump  three_quarter_court_sprint  \\\n",
       "count        1059.000000    1059.000000                 1059.000000   \n",
       "mean           31.829615      25.860157                    3.467047   \n",
       "std             3.423395       3.065653                    0.335502   \n",
       "min            19.000000      14.000000                    2.950000   \n",
       "25%            30.000000      24.000000                    3.339500   \n",
       "50%            31.829615      25.860157                    3.424000   \n",
       "75%            34.000000      28.000000                    3.537500   \n",
       "max            43.500000      38.000000                    9.954000   \n",
       "\n",
       "       four_way_agility  reaction_shuttle     bamscore     wingspan  \\\n",
       "count       1059.000000       1059.000000  1059.000000  1059.000000   \n",
       "mean          12.247189          3.505243  1890.976326    78.089797   \n",
       "std            0.652726          0.273783   134.866028     5.143227   \n",
       "min           10.359000          2.914000  1343.000000    27.000000   \n",
       "25%           11.806000          3.348000  1811.000000    75.500000   \n",
       "50%           12.244000          3.492000  1899.000000    78.000000   \n",
       "75%           12.658000          3.634000  1981.000000    80.500000   \n",
       "max           14.775000          6.759000  2298.000000   150.000000   \n",
       "\n",
       "             reach       height       weight    body_comp  hand_length  \\\n",
       "count  1059.000000  1059.000000  1059.000000  1059.000000  1059.000000   \n",
       "mean     98.714180    75.094195   181.077153    15.007786     8.049381   \n",
       "std       5.824608     5.128197    26.875151     6.016857     0.533210   \n",
       "min       7.500000    37.875000    10.300000     4.000000     4.250000   \n",
       "25%      96.000000    72.750000   165.250000    10.400000     7.750000   \n",
       "50%      98.714180    75.000000   179.600000    14.979496     8.000000   \n",
       "75%     102.000000    77.250000   195.000000    18.900000     8.500000   \n",
       "max     115.000000   190.700000   303.400000    34.500000     9.750000   \n",
       "\n",
       "        hand_width  \n",
       "count  1059.000000  \n",
       "mean      8.876189  \n",
       "std       0.638452  \n",
       "min       4.500000  \n",
       "25%       8.500000  \n",
       "50%       8.876189  \n",
       "75%       9.250000  \n",
       "max      11.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Split Train/Test Data\n",
    "#### 2) - normalize/standardize data with outliers [0,1] - also use min max scalers\n",
    "#### 3) - feature importance\n",
    "#### 4) - random forrest\n",
    "#### 5) - iterate model\n",
    "#### 6) - Find best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/tree.html#classification\n",
    "# https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py\n",
    "# https://towardsdatascience.com/data-science-mistakes-to-avoid-data-leakage-e447f88aae1c\n",
    "### - FIXED DATA LEAKAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Split train/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import tree\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "y = df['bamscore']\n",
    "X = df.drop('bamscore',axis=1) #drop bamscorerank too once I added so no data leakage\n",
    "# y is bamscorerank, x is everything else\n",
    "# now xtrain/split will take those two variables and create two datasets from it\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,\n",
    "                                                 random_state=0, stratify = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0      2003.0\n",
       " 1      1865.0\n",
       " 2      2005.0\n",
       " 3      1902.0\n",
       " 4      1903.0\n",
       "         ...  \n",
       " 789    1916.0\n",
       " 790    1852.0\n",
       " 791    1593.0\n",
       " 792    1814.0\n",
       " 793    2114.0\n",
       " Name: bamscore, Length: 794, dtype: float64, 794     1843.000000\n",
       " 795     1968.000000\n",
       " 796     1965.000000\n",
       " 797     1950.000000\n",
       " 798     1902.000000\n",
       "            ...     \n",
       " 1054    1917.000000\n",
       " 1055    2029.000000\n",
       " 1056    1890.976326\n",
       " 1057    1890.976326\n",
       " 1058    1890.976326\n",
       " Name: bamscore, Length: 265, dtype: float64]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_split(y, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Normalize + Scale Data to adjust for outliers\n",
    "#### - going to use min/max normalization to make all points between 0-1\n",
    "#### - meaning, make data all within 0-1 range. 5.5 on 0-10 scale would be .55 on normalized scale\n",
    "### Why are we normalizing data?\n",
    "#### to make data cleaner, sometimes gets messed up on backend and removes unstructured data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=(y_train-y_train.min())/(y_train.max()-y_train.min())\n",
    "y_test=(y_test-y_test.min())/(y_test.max()-y_test.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize(X_train, copy = False)\n",
    "normalize(X_test, copy = False)\n",
    "df_train = pd.DataFrame(data = np.concatenate((X_train.values, y_train.values.reshape(-1,1)),axis = 1)\n",
    "                        , columns = list(X_train.columns) + [\"bamscore\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approach_vertical</th>\n",
       "      <th>vertical_jump</th>\n",
       "      <th>three_quarter_court_sprint</th>\n",
       "      <th>four_way_agility</th>\n",
       "      <th>reaction_shuttle</th>\n",
       "      <th>wingspan</th>\n",
       "      <th>reach</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>body_comp</th>\n",
       "      <th>hand_length</th>\n",
       "      <th>hand_width</th>\n",
       "      <th>bamscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.127644</td>\n",
       "      <td>0.110904</td>\n",
       "      <td>0.015016</td>\n",
       "      <td>0.049245</td>\n",
       "      <td>0.015585</td>\n",
       "      <td>0.321202</td>\n",
       "      <td>0.401765</td>\n",
       "      <td>0.311786</td>\n",
       "      <td>0.771723</td>\n",
       "      <td>0.092071</td>\n",
       "      <td>0.035573</td>\n",
       "      <td>0.037665</td>\n",
       "      <td>0.603037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.139731</td>\n",
       "      <td>0.113526</td>\n",
       "      <td>0.015712</td>\n",
       "      <td>0.052135</td>\n",
       "      <td>0.014799</td>\n",
       "      <td>0.338029</td>\n",
       "      <td>0.447778</td>\n",
       "      <td>0.340224</td>\n",
       "      <td>0.726981</td>\n",
       "      <td>0.053119</td>\n",
       "      <td>0.032925</td>\n",
       "      <td>0.038412</td>\n",
       "      <td>0.478308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.173806</td>\n",
       "      <td>0.130354</td>\n",
       "      <td>0.016736</td>\n",
       "      <td>0.060029</td>\n",
       "      <td>0.016363</td>\n",
       "      <td>0.370615</td>\n",
       "      <td>0.470297</td>\n",
       "      <td>0.355279</td>\n",
       "      <td>0.675797</td>\n",
       "      <td>0.064410</td>\n",
       "      <td>0.038339</td>\n",
       "      <td>0.039617</td>\n",
       "      <td>0.701735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.108274</td>\n",
       "      <td>0.098607</td>\n",
       "      <td>0.013093</td>\n",
       "      <td>0.046635</td>\n",
       "      <td>0.012846</td>\n",
       "      <td>0.311287</td>\n",
       "      <td>0.407960</td>\n",
       "      <td>0.313221</td>\n",
       "      <td>0.781892</td>\n",
       "      <td>0.032869</td>\n",
       "      <td>0.030935</td>\n",
       "      <td>0.034802</td>\n",
       "      <td>0.587852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.159682</td>\n",
       "      <td>0.126732</td>\n",
       "      <td>0.018128</td>\n",
       "      <td>0.065885</td>\n",
       "      <td>0.017337</td>\n",
       "      <td>0.372591</td>\n",
       "      <td>0.468907</td>\n",
       "      <td>0.357383</td>\n",
       "      <td>0.679282</td>\n",
       "      <td>0.043596</td>\n",
       "      <td>0.040554</td>\n",
       "      <td>0.045623</td>\n",
       "      <td>0.489154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>0.149692</td>\n",
       "      <td>0.128307</td>\n",
       "      <td>0.015715</td>\n",
       "      <td>0.054516</td>\n",
       "      <td>0.016851</td>\n",
       "      <td>0.332649</td>\n",
       "      <td>0.413435</td>\n",
       "      <td>0.318392</td>\n",
       "      <td>0.751786</td>\n",
       "      <td>0.081736</td>\n",
       "      <td>0.035641</td>\n",
       "      <td>0.039205</td>\n",
       "      <td>0.639913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>0.181453</td>\n",
       "      <td>0.144703</td>\n",
       "      <td>0.013625</td>\n",
       "      <td>0.056108</td>\n",
       "      <td>0.015288</td>\n",
       "      <td>0.328452</td>\n",
       "      <td>0.422624</td>\n",
       "      <td>0.321562</td>\n",
       "      <td>0.739132</td>\n",
       "      <td>0.059719</td>\n",
       "      <td>0.035601</td>\n",
       "      <td>0.039047</td>\n",
       "      <td>0.808026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>0.127032</td>\n",
       "      <td>0.098270</td>\n",
       "      <td>0.016855</td>\n",
       "      <td>0.060357</td>\n",
       "      <td>0.015843</td>\n",
       "      <td>0.342747</td>\n",
       "      <td>0.441017</td>\n",
       "      <td>0.333159</td>\n",
       "      <td>0.733430</td>\n",
       "      <td>0.074302</td>\n",
       "      <td>0.041945</td>\n",
       "      <td>0.043143</td>\n",
       "      <td>0.450108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>0.143284</td>\n",
       "      <td>0.115483</td>\n",
       "      <td>0.013507</td>\n",
       "      <td>0.050077</td>\n",
       "      <td>0.013610</td>\n",
       "      <td>0.322924</td>\n",
       "      <td>0.414883</td>\n",
       "      <td>0.316509</td>\n",
       "      <td>0.761332</td>\n",
       "      <td>0.063729</td>\n",
       "      <td>0.035286</td>\n",
       "      <td>0.041702</td>\n",
       "      <td>0.740781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>0.155346</td>\n",
       "      <td>0.168662</td>\n",
       "      <td>0.015299</td>\n",
       "      <td>0.051544</td>\n",
       "      <td>0.015202</td>\n",
       "      <td>0.343981</td>\n",
       "      <td>0.432750</td>\n",
       "      <td>0.327337</td>\n",
       "      <td>0.723470</td>\n",
       "      <td>0.072791</td>\n",
       "      <td>0.037727</td>\n",
       "      <td>0.037727</td>\n",
       "      <td>0.728850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>741 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     approach_vertical  vertical_jump  three_quarter_court_sprint  \\\n",
       "0             0.127644       0.110904                    0.015016   \n",
       "1             0.139731       0.113526                    0.015712   \n",
       "2             0.173806       0.130354                    0.016736   \n",
       "3             0.108274       0.098607                    0.013093   \n",
       "4             0.159682       0.126732                    0.018128   \n",
       "..                 ...            ...                         ...   \n",
       "736           0.149692       0.128307                    0.015715   \n",
       "737           0.181453       0.144703                    0.013625   \n",
       "738           0.127032       0.098270                    0.016855   \n",
       "739           0.143284       0.115483                    0.013507   \n",
       "740           0.155346       0.168662                    0.015299   \n",
       "\n",
       "     four_way_agility  reaction_shuttle  wingspan     reach    height  \\\n",
       "0            0.049245          0.015585  0.321202  0.401765  0.311786   \n",
       "1            0.052135          0.014799  0.338029  0.447778  0.340224   \n",
       "2            0.060029          0.016363  0.370615  0.470297  0.355279   \n",
       "3            0.046635          0.012846  0.311287  0.407960  0.313221   \n",
       "4            0.065885          0.017337  0.372591  0.468907  0.357383   \n",
       "..                ...               ...       ...       ...       ...   \n",
       "736          0.054516          0.016851  0.332649  0.413435  0.318392   \n",
       "737          0.056108          0.015288  0.328452  0.422624  0.321562   \n",
       "738          0.060357          0.015843  0.342747  0.441017  0.333159   \n",
       "739          0.050077          0.013610  0.322924  0.414883  0.316509   \n",
       "740          0.051544          0.015202  0.343981  0.432750  0.327337   \n",
       "\n",
       "       weight  body_comp  hand_length  hand_width  bamscore  \n",
       "0    0.771723   0.092071     0.035573    0.037665  0.603037  \n",
       "1    0.726981   0.053119     0.032925    0.038412  0.478308  \n",
       "2    0.675797   0.064410     0.038339    0.039617  0.701735  \n",
       "3    0.781892   0.032869     0.030935    0.034802  0.587852  \n",
       "4    0.679282   0.043596     0.040554    0.045623  0.489154  \n",
       "..        ...        ...          ...         ...       ...  \n",
       "736  0.751786   0.081736     0.035641    0.039205  0.639913  \n",
       "737  0.739132   0.059719     0.035601    0.039047  0.808026  \n",
       "738  0.733430   0.074302     0.041945    0.043143  0.450108  \n",
       "739  0.761332   0.063729     0.035286    0.041702  0.740781  \n",
       "740  0.723470   0.072791     0.037727    0.037727  0.728850  \n",
       "\n",
       "[741 rows x 13 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Feature Importance + Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.feature_selection import SelectKBest, f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approach_vertical</th>\n",
       "      <th>vertical_jump</th>\n",
       "      <th>three_quarter_court_sprint</th>\n",
       "      <th>four_way_agility</th>\n",
       "      <th>reaction_shuttle</th>\n",
       "      <th>wingspan</th>\n",
       "      <th>reach</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>body_comp</th>\n",
       "      <th>hand_length</th>\n",
       "      <th>hand_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>0.127644</td>\n",
       "      <td>0.110904</td>\n",
       "      <td>0.015016</td>\n",
       "      <td>0.049245</td>\n",
       "      <td>0.015585</td>\n",
       "      <td>0.321202</td>\n",
       "      <td>0.401765</td>\n",
       "      <td>0.311786</td>\n",
       "      <td>0.771723</td>\n",
       "      <td>0.092071</td>\n",
       "      <td>0.035573</td>\n",
       "      <td>0.037665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>0.139731</td>\n",
       "      <td>0.113526</td>\n",
       "      <td>0.015712</td>\n",
       "      <td>0.052135</td>\n",
       "      <td>0.014799</td>\n",
       "      <td>0.338029</td>\n",
       "      <td>0.447778</td>\n",
       "      <td>0.340224</td>\n",
       "      <td>0.726981</td>\n",
       "      <td>0.053119</td>\n",
       "      <td>0.032925</td>\n",
       "      <td>0.038412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>0.173806</td>\n",
       "      <td>0.130354</td>\n",
       "      <td>0.016736</td>\n",
       "      <td>0.060029</td>\n",
       "      <td>0.016363</td>\n",
       "      <td>0.370615</td>\n",
       "      <td>0.470297</td>\n",
       "      <td>0.355279</td>\n",
       "      <td>0.675797</td>\n",
       "      <td>0.064410</td>\n",
       "      <td>0.038339</td>\n",
       "      <td>0.039617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>0.108274</td>\n",
       "      <td>0.098607</td>\n",
       "      <td>0.013093</td>\n",
       "      <td>0.046635</td>\n",
       "      <td>0.012846</td>\n",
       "      <td>0.311287</td>\n",
       "      <td>0.407960</td>\n",
       "      <td>0.313221</td>\n",
       "      <td>0.781892</td>\n",
       "      <td>0.032869</td>\n",
       "      <td>0.030935</td>\n",
       "      <td>0.034802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>0.159682</td>\n",
       "      <td>0.126732</td>\n",
       "      <td>0.018128</td>\n",
       "      <td>0.065885</td>\n",
       "      <td>0.017337</td>\n",
       "      <td>0.372591</td>\n",
       "      <td>0.468907</td>\n",
       "      <td>0.357383</td>\n",
       "      <td>0.679282</td>\n",
       "      <td>0.043596</td>\n",
       "      <td>0.040554</td>\n",
       "      <td>0.045623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>0.149692</td>\n",
       "      <td>0.128307</td>\n",
       "      <td>0.015715</td>\n",
       "      <td>0.054516</td>\n",
       "      <td>0.016851</td>\n",
       "      <td>0.332649</td>\n",
       "      <td>0.413435</td>\n",
       "      <td>0.318392</td>\n",
       "      <td>0.751786</td>\n",
       "      <td>0.081736</td>\n",
       "      <td>0.035641</td>\n",
       "      <td>0.039205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>0.181453</td>\n",
       "      <td>0.144703</td>\n",
       "      <td>0.013625</td>\n",
       "      <td>0.056108</td>\n",
       "      <td>0.015288</td>\n",
       "      <td>0.328452</td>\n",
       "      <td>0.422624</td>\n",
       "      <td>0.321562</td>\n",
       "      <td>0.739132</td>\n",
       "      <td>0.059719</td>\n",
       "      <td>0.035601</td>\n",
       "      <td>0.039047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>0.127032</td>\n",
       "      <td>0.098270</td>\n",
       "      <td>0.016855</td>\n",
       "      <td>0.060357</td>\n",
       "      <td>0.015843</td>\n",
       "      <td>0.342747</td>\n",
       "      <td>0.441017</td>\n",
       "      <td>0.333159</td>\n",
       "      <td>0.733430</td>\n",
       "      <td>0.074302</td>\n",
       "      <td>0.041945</td>\n",
       "      <td>0.043143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0.143284</td>\n",
       "      <td>0.115483</td>\n",
       "      <td>0.013507</td>\n",
       "      <td>0.050077</td>\n",
       "      <td>0.013610</td>\n",
       "      <td>0.322924</td>\n",
       "      <td>0.414883</td>\n",
       "      <td>0.316509</td>\n",
       "      <td>0.761332</td>\n",
       "      <td>0.063729</td>\n",
       "      <td>0.035286</td>\n",
       "      <td>0.041702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>0.155346</td>\n",
       "      <td>0.168662</td>\n",
       "      <td>0.015299</td>\n",
       "      <td>0.051544</td>\n",
       "      <td>0.015202</td>\n",
       "      <td>0.343981</td>\n",
       "      <td>0.432750</td>\n",
       "      <td>0.327337</td>\n",
       "      <td>0.723470</td>\n",
       "      <td>0.072791</td>\n",
       "      <td>0.037727</td>\n",
       "      <td>0.037727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>741 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      approach_vertical  vertical_jump  three_quarter_court_sprint  \\\n",
       "899            0.127644       0.110904                    0.015016   \n",
       "635            0.139731       0.113526                    0.015712   \n",
       "310            0.173806       0.130354                    0.016736   \n",
       "961            0.108274       0.098607                    0.013093   \n",
       "723            0.159682       0.126732                    0.018128   \n",
       "...                 ...            ...                         ...   \n",
       "1033           0.149692       0.128307                    0.015715   \n",
       "763            0.181453       0.144703                    0.013625   \n",
       "835            0.127032       0.098270                    0.016855   \n",
       "559            0.143284       0.115483                    0.013507   \n",
       "684            0.155346       0.168662                    0.015299   \n",
       "\n",
       "      four_way_agility  reaction_shuttle  wingspan     reach    height  \\\n",
       "899           0.049245          0.015585  0.321202  0.401765  0.311786   \n",
       "635           0.052135          0.014799  0.338029  0.447778  0.340224   \n",
       "310           0.060029          0.016363  0.370615  0.470297  0.355279   \n",
       "961           0.046635          0.012846  0.311287  0.407960  0.313221   \n",
       "723           0.065885          0.017337  0.372591  0.468907  0.357383   \n",
       "...                ...               ...       ...       ...       ...   \n",
       "1033          0.054516          0.016851  0.332649  0.413435  0.318392   \n",
       "763           0.056108          0.015288  0.328452  0.422624  0.321562   \n",
       "835           0.060357          0.015843  0.342747  0.441017  0.333159   \n",
       "559           0.050077          0.013610  0.322924  0.414883  0.316509   \n",
       "684           0.051544          0.015202  0.343981  0.432750  0.327337   \n",
       "\n",
       "        weight  body_comp  hand_length  hand_width  \n",
       "899   0.771723   0.092071     0.035573    0.037665  \n",
       "635   0.726981   0.053119     0.032925    0.038412  \n",
       "310   0.675797   0.064410     0.038339    0.039617  \n",
       "961   0.781892   0.032869     0.030935    0.034802  \n",
       "723   0.679282   0.043596     0.040554    0.045623  \n",
       "...        ...        ...          ...         ...  \n",
       "1033  0.751786   0.081736     0.035641    0.039205  \n",
       "763   0.739132   0.059719     0.035601    0.039047  \n",
       "835   0.733430   0.074302     0.041945    0.043143  \n",
       "559   0.761332   0.063729     0.035286    0.041702  \n",
       "684   0.723470   0.072791     0.037727    0.037727  \n",
       "\n",
       "[741 rows x 12 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# want to fit and transform the model on training x and y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skb = SelectKBest(f_regression, k=8)\n",
    "skb = SelectKBest(score_func=f_regression, k=5)\n",
    "fit = skb.fit(X_train, y_train)\n",
    "features = fit.transform(X_train)\n",
    "#X_new = SelectKBest(chi2, k=20).fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approach_vertical</th>\n",
       "      <th>vertical_jump</th>\n",
       "      <th>wingspan</th>\n",
       "      <th>weight</th>\n",
       "      <th>hand_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>0.127644</td>\n",
       "      <td>0.110904</td>\n",
       "      <td>0.321202</td>\n",
       "      <td>0.771723</td>\n",
       "      <td>0.037665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>0.139731</td>\n",
       "      <td>0.113526</td>\n",
       "      <td>0.338029</td>\n",
       "      <td>0.726981</td>\n",
       "      <td>0.038412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>0.173806</td>\n",
       "      <td>0.130354</td>\n",
       "      <td>0.370615</td>\n",
       "      <td>0.675797</td>\n",
       "      <td>0.039617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>0.108274</td>\n",
       "      <td>0.098607</td>\n",
       "      <td>0.311287</td>\n",
       "      <td>0.781892</td>\n",
       "      <td>0.034802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>0.159682</td>\n",
       "      <td>0.126732</td>\n",
       "      <td>0.372591</td>\n",
       "      <td>0.679282</td>\n",
       "      <td>0.045623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>0.149692</td>\n",
       "      <td>0.128307</td>\n",
       "      <td>0.332649</td>\n",
       "      <td>0.751786</td>\n",
       "      <td>0.039205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>0.181453</td>\n",
       "      <td>0.144703</td>\n",
       "      <td>0.328452</td>\n",
       "      <td>0.739132</td>\n",
       "      <td>0.039047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>0.127032</td>\n",
       "      <td>0.098270</td>\n",
       "      <td>0.342747</td>\n",
       "      <td>0.733430</td>\n",
       "      <td>0.043143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0.143284</td>\n",
       "      <td>0.115483</td>\n",
       "      <td>0.322924</td>\n",
       "      <td>0.761332</td>\n",
       "      <td>0.041702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>0.155346</td>\n",
       "      <td>0.168662</td>\n",
       "      <td>0.343981</td>\n",
       "      <td>0.723470</td>\n",
       "      <td>0.037727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>741 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      approach_vertical  vertical_jump  wingspan    weight  hand_width\n",
       "899            0.127644       0.110904  0.321202  0.771723    0.037665\n",
       "635            0.139731       0.113526  0.338029  0.726981    0.038412\n",
       "310            0.173806       0.130354  0.370615  0.675797    0.039617\n",
       "961            0.108274       0.098607  0.311287  0.781892    0.034802\n",
       "723            0.159682       0.126732  0.372591  0.679282    0.045623\n",
       "...                 ...            ...       ...       ...         ...\n",
       "1033           0.149692       0.128307  0.332649  0.751786    0.039205\n",
       "763            0.181453       0.144703  0.328452  0.739132    0.039047\n",
       "835            0.127032       0.098270  0.342747  0.733430    0.043143\n",
       "559            0.143284       0.115483  0.322924  0.761332    0.041702\n",
       "684            0.155346       0.168662  0.343981  0.723470    0.037727\n",
       "\n",
       "[741 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = fit.get_support()\n",
    "X_train[X_train.columns[mask]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True False False False  True False False  True False False  True]\n",
      "[[0.12764397 0.11090378 0.32120246 0.77172292 0.03766544]\n",
      " [0.13973142 0.11352561 0.33802858 0.72698095 0.03841234]\n",
      " [0.17380558 0.13035419 0.37061485 0.675797   0.03961745]\n",
      " ...\n",
      " [0.12703203 0.09827006 0.34274681 0.73343023 0.04314295]\n",
      " [0.14328437 0.11548293 0.32292448 0.76133189 0.04170217]\n",
      " [0.15534627 0.16866167 0.34398103 0.72346978 0.03772695]]\n",
      "(741, 5)\n"
     ]
    }
   ],
   "source": [
    "print(mask)\n",
    "print(features)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OLS Regression (Ordinary Least Squares)\n",
    "### Use this because it's the most simple baseline model\n",
    "### Model gives best approximate of true population regression line.\n",
    "### The principle of OLS is to minimize the square of errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               bamscore   R-squared:                       0.619\n",
      "Model:                            OLS   Adj. R-squared:                  0.617\n",
      "Method:                 Least Squares   F-statistic:                     398.5\n",
      "Date:                Mon, 25 Apr 2022   Prob (F-statistic):          8.99e-154\n",
      "Time:                        12:02:45   Log-Likelihood:                 714.13\n",
      "No. Observations:                 741   AIC:                            -1420.\n",
      "Df Residuals:                     737   BIC:                            -1402.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=====================================================================================\n",
      "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "Intercept             0.5078      0.034     15.015      0.000       0.441       0.574\n",
      "approach_vertical     3.9594      0.365     10.837      0.000       3.242       4.677\n",
      "vertical_jump         3.3054      0.414      7.976      0.000       2.492       4.119\n",
      "four_way_agility    -16.3254      0.752    -21.718      0.000     -17.801     -14.850\n",
      "==============================================================================\n",
      "Omnibus:                       72.121   Durbin-Watson:                   2.015\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              219.234\n",
      "Skew:                          -0.459   Prob(JB):                     2.48e-48\n",
      "Kurtosis:                       5.502   Cond. No.                         229.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "After selecting best 3 features: (741, 5)\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "formula = \"bamscore ~ approach_vertical + vertical_jump + four_way_agility\"\n",
    "lm = smf.ols(formula = formula, data = df_train).fit()\n",
    "print(lm.summary())\n",
    "print(\"After selecting best 3 features:\", features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### df = samplesize - # of variables +1 --> number of independent observations\n",
    "### constant is intercept in regression line and tells us avg value of ommited variables and noise in model\n",
    "### coeff term = slope aka rise over run, if x increases by 1 , and coeff is .7, y increased by .7\n",
    "### standard error = std\n",
    "### Standard error shows the sampling variability of these parameters.o^2 is equal to residual sum squares\n",
    "#### remember *o2 in first param and its the numerator in second param\n",
    "\n",
    "### H0  : B2  = 0       ( variable X has no influence on Y) \n",
    "### Ha  : B2  ≠ 0      (X has significant impact on Y)\n",
    "### b1  ∼ N(B1, σb12) B1 is true mean of b1\n",
    "### - b1 is param\n",
    "### b2   ∼ N(B2 , σb22) B2 is true mean of b2\n",
    "### - b2 is param\n",
    "\n",
    "### p value - reject null <0.05 or fail to reject if >0.05. if 0 t is probably high\n",
    "\n",
    "### R2 is the coefficient of determination that tells us that\n",
    "### how much percentage variation independent variable can be explained by independent variable.\n",
    "\n",
    "# F stat - prob f stat > f stat given = 0 means reject null\n",
    "\n",
    "### https://www.geeksforgeeks.org/interpreting-the-results-of-linear-regression-using-ols-summary/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add features to try and improve r2 + find important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               bamscore   R-squared:                       0.623\n",
      "Model:                            OLS   Adj. R-squared:                  0.620\n",
      "Method:                 Least Squares   F-statistic:                     202.5\n",
      "Date:                Mon, 25 Apr 2022   Prob (F-statistic):          5.79e-152\n",
      "Time:                        12:02:45   Log-Likelihood:                 718.80\n",
      "No. Observations:                 741   AIC:                            -1424.\n",
      "Df Residuals:                     734   BIC:                            -1391.\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=====================================================================================\n",
      "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "Intercept             0.9057      0.167      5.412      0.000       0.577       1.234\n",
      "approach_vertical     3.8064      0.370     10.301      0.000       3.081       4.532\n",
      "vertical_jump         3.1563      0.417      7.568      0.000       2.338       3.975\n",
      "reach                -0.0871      0.168     -0.519      0.604      -0.416       0.242\n",
      "weight               -0.3362      0.125     -2.699      0.007      -0.581      -0.092\n",
      "body_comp            -0.0270      0.158     -0.171      0.864      -0.337       0.283\n",
      "four_way_agility    -17.6547      0.904    -19.536      0.000     -19.429     -15.881\n",
      "==============================================================================\n",
      "Omnibus:                       73.223   Durbin-Watson:                   2.011\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              227.170\n",
      "Skew:                          -0.460   Prob(JB):                     4.68e-50\n",
      "Kurtosis:                       5.552   Cond. No.                         360.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[ True  True False False False  True False False  True False False  True]\n",
      "[[0.12764397 0.11090378 0.32120246 0.77172292 0.03766544]\n",
      " [0.13973142 0.11352561 0.33802858 0.72698095 0.03841234]\n",
      " [0.17380558 0.13035419 0.37061485 0.675797   0.03961745]\n",
      " ...\n",
      " [0.12703203 0.09827006 0.34274681 0.73343023 0.04314295]\n",
      " [0.14328437 0.11548293 0.32292448 0.76133189 0.04170217]\n",
      " [0.15534627 0.16866167 0.34398103 0.72346978 0.03772695]]\n",
      "(741, 5)\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "formula = \"bamscore ~ approach_vertical + vertical_jump + reach + weight + body_comp + four_way_agility\"\n",
    "lm = smf.ols(formula = formula, data = df_train).fit()\n",
    "print(lm.summary())\n",
    "print(mask)\n",
    "print(features)\n",
    "print(features.shape)\n",
    "#https://www.datatechnotes.com/2021/02/seleckbest-feature-selection-example-in-python.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# body comp and weight >0.05 - Ideally just drop them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteration - I wanted to take out because it is hard to measure already, now we know we can take it out because it's really throwing off the data and martin said it does not matter much, but model does not know that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               bamscore   R-squared:                       0.620\n",
      "Model:                            OLS   Adj. R-squared:                  0.618\n",
      "Method:                 Least Squares   F-statistic:                     299.8\n",
      "Date:                Mon, 25 Apr 2022   Prob (F-statistic):          7.16e-153\n",
      "Time:                        12:02:45   Log-Likelihood:                 715.14\n",
      "No. Observations:                 741   AIC:                            -1420.\n",
      "Df Residuals:                     736   BIC:                            -1397.\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=====================================================================================\n",
      "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "Intercept             0.4708      0.043     11.028      0.000       0.387       0.555\n",
      "approach_vertical     3.9304      0.366     10.749      0.000       3.213       4.648\n",
      "vertical_jump         3.2492      0.416      7.810      0.000       2.432       4.066\n",
      "reach                 0.1890      0.133      1.418      0.157      -0.073       0.451\n",
      "four_way_agility    -16.9350      0.866    -19.566      0.000     -18.634     -15.236\n",
      "==============================================================================\n",
      "Omnibus:                       69.439   Durbin-Watson:                   2.018\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              228.944\n",
      "Skew:                          -0.410   Prob(JB):                     1.93e-50\n",
      "Kurtosis:                       5.597   Cond. No.                         283.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7ff491df7fd0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "formula = \"bamscore ~ approach_vertical + vertical_jump + reach + four_way_agility\"\n",
    "lm = smf.ols(formula = formula, data = df_train).fit()\n",
    "print(lm.summary())\n",
    "sns.lmplot(x=\"four_way_agility\", y=\"bamscore\" ,data=df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteration - features I think are most important from pairplot in EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               bamscore   R-squared:                       0.697\n",
      "Model:                            OLS   Adj. R-squared:                  0.695\n",
      "Method:                 Least Squares   F-statistic:                     337.9\n",
      "Date:                Mon, 25 Apr 2022   Prob (F-statistic):          1.01e-187\n",
      "Time:                        12:02:46   Log-Likelihood:                 799.16\n",
      "No. Observations:                 741   AIC:                            -1586.\n",
      "Df Residuals:                     735   BIC:                            -1559.\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================================\n",
      "                                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------\n",
      "Intercept                      0.5582      0.030     18.313      0.000       0.498       0.618\n",
      "three_quarter_court_sprint    -7.9533      1.923     -4.136      0.000     -11.728      -4.179\n",
      "four_way_agility              -6.0437      1.019     -5.932      0.000      -8.044      -4.044\n",
      "reaction_shuttle             -35.3052      2.773    -12.732      0.000     -40.749     -29.861\n",
      "vertical_jump                  3.2517      0.370      8.788      0.000       2.525       3.978\n",
      "approach_vertical              4.4234      0.328     13.489      0.000       3.780       5.067\n",
      "==============================================================================\n",
      "Omnibus:                       76.718   Durbin-Watson:                   2.017\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              457.485\n",
      "Skew:                          -0.204   Prob(JB):                    4.55e-100\n",
      "Kurtosis:                       6.828   Cond. No.                         955.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "formula = \"bamscore ~ three_quarter_court_sprint + four_way_agility + reaction_shuttle + vertical_jump + approach_vertical\"\n",
    "lm = smf.ols(formula = formula, data = df_train).fit()\n",
    "print(lm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           GLSAR Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               bamscore   R-squared:                       0.697\n",
      "Model:                          GLSAR   Adj. R-squared:                  0.695\n",
      "Method:                 Least Squares   F-statistic:                     338.1\n",
      "Date:                Mon, 25 Apr 2022   Prob (F-statistic):          1.10e-187\n",
      "Time:                        12:02:46   Log-Likelihood:                 798.14\n",
      "No. Observations:                 740   AIC:                            -1584.\n",
      "Df Residuals:                     734   BIC:                            -1557.\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================================\n",
      "                                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------\n",
      "Intercept                      0.5579      0.030     18.301      0.000       0.498       0.618\n",
      "three_quarter_court_sprint    -7.9910      1.923     -4.156      0.000     -11.766      -4.216\n",
      "four_way_agility              -5.9933      1.020     -5.877      0.000      -7.995      -3.991\n",
      "reaction_shuttle             -35.4437      2.776    -12.769      0.000     -40.893     -29.994\n",
      "vertical_jump                  3.2400      0.370      8.753      0.000       2.513       3.967\n",
      "approach_vertical              4.4347      0.328     13.518      0.000       3.791       5.079\n",
      "==============================================================================\n",
      "Omnibus:                       76.581   Durbin-Watson:                   2.013\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              458.040\n",
      "Skew:                          -0.201   Prob(JB):                    3.45e-100\n",
      "Kurtosis:                       6.833   Cond. No.                         955.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as sm\n",
    "model = sm.glsar(formula = formula, data = df_train)\n",
    "\n",
    "lm = model.fit()\n",
    "print(lm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3491785846088724"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO LM PLOT to see trend in data with respect to bamscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "## Going to try random forrest because we had over fitting in models above\n",
    "## Random forrest corrects for high variance/overfitting by using many decision trees\n",
    "\n",
    "#Steps:\n",
    "# -create bootstrapped dataset with subset of variables\n",
    "# -fit decision tree\n",
    "# -repeat and tally predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5295593565201384"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    " \n",
    "# create regressor object\n",
    "regressor = RandomForestRegressor(n_estimators = 100, random_state = 0)\n",
    "cols = [\"four_way_agility\", \"reaction_shuttle\", \"three_quarter_court_sprint\", \"vertical_jump\", \"approach_vertical\"]\n",
    "# fit the regressor with x and y data\n",
    "rf = regressor.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)\n",
    "# score if fit and test on full data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5382597305545691"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x_train[cols]\n",
    "#x_test[cols]\n",
    "\n",
    "regressor = RandomForestRegressor(n_estimators = 100, random_state = 0)\n",
    "cols = [\"four_way_agility\", \"reaction_shuttle\", \"three_quarter_court_sprint\", \"vertical_jump\", \"approach_vertical\"]\n",
    "# fit the regressor with x and y data\n",
    "rf = regressor.fit(X_train[cols], y_train)\n",
    "rf.score(X_test[cols], y_test)\n",
    "# score if fit and test on just [cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If Condition Number is too high I'll run into problems in matrix because program may not catch small errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Iterative modeling process\n",
    "### What models are appropriate\n",
    "### Compare Models\n",
    "### Find which performance metrics to use and adjust to make the model better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Assumptions to test in model:\n",
    "#### - Combine Tests more important than physical measurments. Weigh combine tests as double.\n",
    "#### - just tests, just measurments, 1:1 test/measurements, hypothesis - 2:1 test/measurment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r2 = model isn't very accurate predicting bamscore with .453 bamscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Least Sum Squares to figure out best fit line and figure out most correlated features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
